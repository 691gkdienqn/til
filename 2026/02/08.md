# 2026-02-08 TIL (GridSearch 중단 기록)

## 오늘 한 줄 요약
GridSearch(288 candidates × CV5 = 1440 fits)를 실제로 돌려보며 “계속 돌릴 가치가 있는가?”를 고민했고, 시간 대비 효율이 낮다고 판단해 중단했다.

---

## 내가 시도한 것
- GridSearchCV로 Stacking 모델 튜닝
- 설정
  - Grid candidates: 288
  - CV folds: 5
  - Total fits: 1440
  - n_jobs=1, verbose=3

실제 로그에서 확인한 1 fit(=한 fold, 한 조합) 시간
- 약 11~15초(대부분 11~12초대)

---

## 왜 중단했나 (수치 기반 판단)
대략적인 총 소요 시간 추정
- 1440 fits × 평균 12초 ≈ 17,280초 ≈ 4.8시간

Stacking + (LGBM, XGB 동시 튜닝) + CV=5 조합은 탐색 범위 대비 시간 비용이 너무 컸다.

---

## 오늘 배운 핵심
### 1) GridSearch는 시간이 “조합 수 × CV”로 폭발한다
- candidates가 288이면, CV=5에서 1440번 학습은 구조적으로 피할 수 없다.

### 2) verbose가 안 찍힐 때는 ‘멈춤’이 아닐 수 있다
- Colab에서 출력 버퍼링/환경 꼬임으로 로그가 늦게 뜰 수 있다.
- Runtime 재시작 후 n_jobs=1로 돌리니 로그가 정상 출력되었다.

### 3) 스태킹에서 (베이스+메타) 파라미터를 한 번에 크게 튜닝하면 비효율적이다
- 베이스 모델(LGBM/XGB) 파라미터 + 메타(LogReg) 파라미터를 동시에 넓게 돌리면
  시간만 크게 늘고 가성비가 나빠질 수 있다.

---

## 다음에 다시 한다면 (내 전략)

### Step 1. 탐색은 RandomizedSearchCV로 (빠르게)
- GridSearch → RandomizedSearchCV
- n_iter: 30~60
- CV: 3 (탐색용)
- 목표 지표: F1 (목표와 scoring 일치)

### Step 2. 정밀화는 “best 근처만” 작은 GridSearch
- Randomized best 근처에서만 좁은 범위로 GridSearch
- 이때만 CV=5로 최종 확인

### Step 3. (스태킹 튜닝 순서)
- (1) 베이스 모델들 먼저 적당히 튜닝
- (2) 마지막에 meta(final_estimator)만 튜닝
- 한 번에 (베이스+메타) 모두 큰 Grid로 돌리지 않는다.

### Step 4. 코랩에서 멈춤/무응답 방지 팁
- 진행 확인을 위해 verbose를 올리고(n_jobs=1로 먼저 확인),
- 정상 동작 확인 후에만 병렬(n_jobs=-1)을 시도한다.
- “중첩 병렬”(GridSearch도 -1, 모델도 -1)은 피한다.

---

## 오늘의 결론
> “끝까지 돌리는 것”이 목표가 아니라 “좋은 모델을 얻는 것”이 목표!   
> 오래 걸리는 실험은 시간 대비 효율이 낮을 수 있으니,  
> 그리드를 줄이거나(Randomized → small Grid) 빠르게 best를 찾는 전략이 더 현명하다.

